{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from eunjeon import Mecab\n",
    "\n",
    "okt = Okt()\n",
    "kkma = Kkma()\n",
    "kom = Komoran()\n",
    "mecab = Mecab()\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-112-e6109558c4ff>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-112-e6109558c4ff>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission=pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=train[['과제명','요약문_연구내용','label']]\n",
    "test1=test[['과제명','요약문_연구내용']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=train[['과제명','label']]\n",
    "test2=test[['과제명']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw=train1['과제명'] + train1['요약문_연구내용']\n",
    "test_raw=test1['과제명'] + test1['요약문_연구내용']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제명 + 요약문_연구내용\n",
    "# 패딩을 40, 400으로 다르게 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "temp2=[]\n",
    "for i in range(0,len(train_raw)):\n",
    "    temp.append(okt.nouns(str(train_raw[i])))\n",
    "for i in range(0,len(test_raw)):\n",
    "    temp2.append(okt.nouns(str(test_raw[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(temp)\n",
    "tokenizer.fit_on_texts(temp2)\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(temp)\n",
    "test_sequences=tokenizer.texts_to_sequences(temp2)\n",
    "word_vocab=tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs=pad_sequences(train_sequences, maxlen=40, padding='post')\n",
    "test_inputs=pad_sequences(test_sequences, maxlen=40, padding='post')\n",
    "\n",
    "train_inputs2=pad_sequences(train_sequences, maxlen=400, padding='post')\n",
    "test_inputs2=pad_sequences(test_sequences, maxlen=400, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 40\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 40, 32)            2127744   \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,137,902\n",
      "Trainable params: 2,137,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array(train['label'])\n",
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4358/4358 [==============================] - 74s 16ms/step - loss: 0.8725 - accuracy: 0.8224 - val_loss: 0.7278 - val_accuracy: 0.8285\n",
      "Epoch 2/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.6059 - accuracy: 0.8440 - val_loss: 0.6172 - val_accuracy: 0.8448\n",
      "Epoch 3/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.4820 - accuracy: 0.8675 - val_loss: 0.5767 - val_accuracy: 0.8531\n",
      "Epoch 4/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.4002 - accuracy: 0.8861 - val_loss: 0.5754 - val_accuracy: 0.8582\n",
      "Epoch 5/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.3436 - accuracy: 0.8999 - val_loss: 0.5877 - val_accuracy: 0.8613\n",
      "Epoch 6/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.2992 - accuracy: 0.9118 - val_loss: 0.6065 - val_accuracy: 0.8623\n",
      "Epoch 7/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.2630 - accuracy: 0.9224 - val_loss: 0.6322 - val_accuracy: 0.8647\n",
      "Epoch 8/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.2320 - accuracy: 0.9319 - val_loss: 0.6598 - val_accuracy: 0.8606\n",
      "Epoch 9/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.2054 - accuracy: 0.9392 - val_loss: 0.6931 - val_accuracy: 0.8635\n",
      "Epoch 10/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.1824 - accuracy: 0.9458 - val_loss: 0.7262 - val_accuracy: 0.8619\n",
      "Epoch 11/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.1614 - accuracy: 0.9524 - val_loss: 0.7731 - val_accuracy: 0.8625\n",
      "Epoch 12/30\n",
      "4358/4358 [==============================] - 68s 16ms/step - loss: 0.1445 - accuracy: 0.9573 - val_loss: 0.8113 - val_accuracy: 0.8585\n",
      "Epoch 13/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.1284 - accuracy: 0.9620 - val_loss: 0.8489 - val_accuracy: 0.8590\n",
      "Epoch 14/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.1155 - accuracy: 0.9659 - val_loss: 0.9077 - val_accuracy: 0.8582\n",
      "Epoch 15/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.1040 - accuracy: 0.9698 - val_loss: 0.9499 - val_accuracy: 0.8574\n",
      "Epoch 16/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0941 - accuracy: 0.9724 - val_loss: 0.9988 - val_accuracy: 0.8553\n",
      "Epoch 17/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0855 - accuracy: 0.9751 - val_loss: 1.0472 - val_accuracy: 0.8603\n",
      "Epoch 18/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0782 - accuracy: 0.9774 - val_loss: 1.0963 - val_accuracy: 0.8600\n",
      "Epoch 19/30\n",
      "4358/4358 [==============================] - 68s 16ms/step - loss: 0.0714 - accuracy: 0.9796 - val_loss: 1.1540 - val_accuracy: 0.8586\n",
      "Epoch 20/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0659 - accuracy: 0.9814 - val_loss: 1.1909 - val_accuracy: 0.8596\n",
      "Epoch 21/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0624 - accuracy: 0.9825 - val_loss: 1.2202 - val_accuracy: 0.8552\n",
      "Epoch 22/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0584 - accuracy: 0.9837 - val_loss: 1.2598 - val_accuracy: 0.8590\n",
      "Epoch 23/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0549 - accuracy: 0.9848 - val_loss: 1.3040 - val_accuracy: 0.8562\n",
      "Epoch 24/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0523 - accuracy: 0.9859 - val_loss: 1.3312 - val_accuracy: 0.8554\n",
      "Epoch 25/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0505 - accuracy: 0.9863 - val_loss: 1.3593 - val_accuracy: 0.8536\n",
      "Epoch 26/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0486 - accuracy: 0.9867 - val_loss: 1.3983 - val_accuracy: 0.8547\n",
      "Epoch 27/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 1.4205 - val_accuracy: 0.8544\n",
      "Epoch 28/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 1.4635 - val_accuracy: 0.8538\n",
      "Epoch 29/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0438 - accuracy: 0.9882 - val_loss: 1.4772 - val_accuracy: 0.8440\n",
      "Epoch 30/30\n",
      "4358/4358 [==============================] - 69s 16ms/step - loss: 0.0434 - accuracy: 0.9880 - val_loss: 1.4958 - val_accuracy: 0.8512\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "num_epochs = 30\n",
    "history = model.fit(train_inputs, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(test_inputs)\n",
    "pred=tf.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=pred\n",
    "sample_submission.to_csv('패딩40 okt nouns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 400, 32)           2127744   \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,137,902\n",
      "Trainable params: 2,137,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 400\n",
    "oov_tok = \"<OOV>\"\n",
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4358/4358 [==============================] - 74s 17ms/step - loss: 0.6698 - accuracy: 0.8337 - val_loss: 0.6353 - val_accuracy: 0.8373\n",
      "Epoch 2/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.5347 - accuracy: 0.8564 - val_loss: 0.5613 - val_accuracy: 0.8525\n",
      "Epoch 3/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.4441 - accuracy: 0.8751 - val_loss: 0.5246 - val_accuracy: 0.8623\n",
      "Epoch 4/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.3781 - accuracy: 0.8908 - val_loss: 0.5010 - val_accuracy: 0.8705\n",
      "Epoch 5/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.3282 - accuracy: 0.9038 - val_loss: 0.4989 - val_accuracy: 0.8744\n",
      "Epoch 6/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.2888 - accuracy: 0.9144 - val_loss: 0.5010 - val_accuracy: 0.8777\n",
      "Epoch 7/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.2559 - accuracy: 0.9241 - val_loss: 0.5110 - val_accuracy: 0.8789\n",
      "Epoch 8/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.2275 - accuracy: 0.9319 - val_loss: 0.5329 - val_accuracy: 0.8780\n",
      "Epoch 9/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.2040 - accuracy: 0.9388 - val_loss: 0.5582 - val_accuracy: 0.8827\n",
      "Epoch 10/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.1823 - accuracy: 0.9443 - val_loss: 0.5688 - val_accuracy: 0.8834\n",
      "Epoch 11/30\n",
      "4358/4358 [==============================] - 70s 16ms/step - loss: 0.1636 - accuracy: 0.9503 - val_loss: 0.5862 - val_accuracy: 0.8866\n",
      "Epoch 12/30\n",
      "4358/4358 [==============================] - 70s 16ms/step - loss: 0.1476 - accuracy: 0.9549 - val_loss: 0.6210 - val_accuracy: 0.8878\n",
      "Epoch 13/30\n",
      "4358/4358 [==============================] - 72s 16ms/step - loss: 0.1328 - accuracy: 0.9600 - val_loss: 0.6396 - val_accuracy: 0.8865\n",
      "Epoch 14/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.1192 - accuracy: 0.9635 - val_loss: 0.6843 - val_accuracy: 0.8846\n",
      "Epoch 15/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.1088 - accuracy: 0.9668 - val_loss: 0.7124 - val_accuracy: 0.8880\n",
      "Epoch 16/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0990 - accuracy: 0.9699 - val_loss: 0.7347 - val_accuracy: 0.8826\n",
      "Epoch 17/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0903 - accuracy: 0.9726 - val_loss: 0.7520 - val_accuracy: 0.8813\n",
      "Epoch 18/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0834 - accuracy: 0.9749 - val_loss: 0.8039 - val_accuracy: 0.8883\n",
      "Epoch 19/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0774 - accuracy: 0.9771 - val_loss: 0.8220 - val_accuracy: 0.8763\n",
      "Epoch 20/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0716 - accuracy: 0.9787 - val_loss: 0.8425 - val_accuracy: 0.8790\n",
      "Epoch 21/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0664 - accuracy: 0.9806 - val_loss: 0.8609 - val_accuracy: 0.8815\n",
      "Epoch 22/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0628 - accuracy: 0.9818 - val_loss: 0.8915 - val_accuracy: 0.8816\n",
      "Epoch 23/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0597 - accuracy: 0.9825 - val_loss: 0.9607 - val_accuracy: 0.8756\n",
      "Epoch 24/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0567 - accuracy: 0.9835 - val_loss: 0.9772 - val_accuracy: 0.8843\n",
      "Epoch 25/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0531 - accuracy: 0.9844 - val_loss: 0.9801 - val_accuracy: 0.8841\n",
      "Epoch 26/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0514 - accuracy: 0.9850 - val_loss: 1.0062 - val_accuracy: 0.8813\n",
      "Epoch 27/30\n",
      "4358/4358 [==============================] - 70s 16ms/step - loss: 0.0494 - accuracy: 0.9856 - val_loss: 1.0183 - val_accuracy: 0.8850\n",
      "Epoch 28/30\n",
      "4358/4358 [==============================] - 70s 16ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 1.0792 - val_accuracy: 0.8881\n",
      "Epoch 29/30\n",
      "4358/4358 [==============================] - 70s 16ms/step - loss: 0.0455 - accuracy: 0.9870 - val_loss: 1.0596 - val_accuracy: 0.8826\n",
      "Epoch 30/30\n",
      "4358/4358 [==============================] - 71s 16ms/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 1.1135 - val_accuracy: 0.8874\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "num_epochs = 30\n",
    "history = model.fit(train_inputs2, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=model.predict(test_inputs2)\n",
    "pred2=tf.argmax(pred2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=pred2\n",
    "sample_submission.to_csv('패딩400 okt nouns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 처리 다르게 적용\n",
    "stop_w=pd.read_csv(\"stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(text, okt, remove_stopwords=False, stop_words=[]):\n",
    "    text=re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ]\",\"\", text)\n",
    "    word_text=okt.morphs(text, stem=True)\n",
    "    if remove_stopwords:\n",
    "        word_text=[token for token in word_text if not token in stop_words]\n",
    "    return word_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words=list(stop_w)\n",
    "clean_train_text=[]\n",
    "clean_test_text=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 174304/174304 [23:59<00:00, 121.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#시간이 많이 걸립니다.\n",
    "for text in tqdm.tqdm(train['과제명']):\n",
    "    try:\n",
    "        clean_train_text.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    except:\n",
    "        clean_train_text.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 43576/43576 [06:31<00:00, 111.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm.tqdm(test['과제명']):\n",
    "    if type(text) == str:\n",
    "        clean_test_text.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        clean_test_text.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_text)\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(clean_train_text)\n",
    "test_sequences=tokenizer.texts_to_sequences(clean_test_text)\n",
    "word_vocab=tokenizer.word_index\n",
    "\n",
    "#패딩 처리\n",
    "train_inputs3=pad_sequences(train_sequences, maxlen=40, padding='post')\n",
    "test_inputs3=pad_sequences(test_sequences, maxlen=40, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array(train['label'])\n",
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 32)            1046464   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 32)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,056,622\n",
      "Trainable params: 1,056,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "labels=np.array(train['label'])\n",
    "len(set(labels))\n",
    "\n",
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 40\n",
    "oov_tok = \"<OOV>\"\n",
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4358/4358 [==============================] - 35s 7ms/step - loss: 0.9369 - accuracy: 0.8193 - val_loss: 0.8266 - val_accuracy: 0.8235\n",
      "Epoch 2/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.6927 - accuracy: 0.8359 - val_loss: 0.6515 - val_accuracy: 0.8425\n",
      "Epoch 3/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.5472 - accuracy: 0.8596 - val_loss: 0.5848 - val_accuracy: 0.8532\n",
      "Epoch 4/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.4533 - accuracy: 0.8781 - val_loss: 0.5336 - val_accuracy: 0.8660\n",
      "Epoch 5/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.3829 - accuracy: 0.8938 - val_loss: 0.5000 - val_accuracy: 0.8732\n",
      "Epoch 6/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.3311 - accuracy: 0.9057 - val_loss: 0.4881 - val_accuracy: 0.8777\n",
      "Epoch 7/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.2934 - accuracy: 0.9149 - val_loss: 0.4743 - val_accuracy: 0.8807\n",
      "Epoch 8/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.2635 - accuracy: 0.9222 - val_loss: 0.4694 - val_accuracy: 0.8864\n",
      "Epoch 9/30\n",
      "4358/4358 [==============================] - 32s 7ms/step - loss: 0.2399 - accuracy: 0.9290 - val_loss: 0.4827 - val_accuracy: 0.8880\n",
      "Epoch 10/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.2205 - accuracy: 0.9340 - val_loss: 0.4808 - val_accuracy: 0.8884\n",
      "Epoch 11/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.2037 - accuracy: 0.9387 - val_loss: 0.4836 - val_accuracy: 0.8932\n",
      "Epoch 12/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1905 - accuracy: 0.9422 - val_loss: 0.4975 - val_accuracy: 0.8924\n",
      "Epoch 13/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1774 - accuracy: 0.9460 - val_loss: 0.5102 - val_accuracy: 0.8931\n",
      "Epoch 14/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1668 - accuracy: 0.9491 - val_loss: 0.5151 - val_accuracy: 0.8939\n",
      "Epoch 15/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1567 - accuracy: 0.9521 - val_loss: 0.5261 - val_accuracy: 0.8929\n",
      "Epoch 16/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1478 - accuracy: 0.9544 - val_loss: 0.5424 - val_accuracy: 0.8932\n",
      "Epoch 17/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1393 - accuracy: 0.9571 - val_loss: 0.5573 - val_accuracy: 0.8941\n",
      "Epoch 18/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1319 - accuracy: 0.9594 - val_loss: 0.5681 - val_accuracy: 0.8925\n",
      "Epoch 19/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1249 - accuracy: 0.9608 - val_loss: 0.5793 - val_accuracy: 0.8912\n",
      "Epoch 20/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1187 - accuracy: 0.9634 - val_loss: 0.5986 - val_accuracy: 0.8947\n",
      "Epoch 21/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1131 - accuracy: 0.9651 - val_loss: 0.6043 - val_accuracy: 0.8950\n",
      "Epoch 22/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1071 - accuracy: 0.9665 - val_loss: 0.6213 - val_accuracy: 0.8962\n",
      "Epoch 23/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.1023 - accuracy: 0.9673 - val_loss: 0.6375 - val_accuracy: 0.8968\n",
      "Epoch 24/30\n",
      "4358/4358 [==============================] - 32s 7ms/step - loss: 0.0972 - accuracy: 0.9689 - val_loss: 0.6613 - val_accuracy: 0.8955\n",
      "Epoch 25/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.0931 - accuracy: 0.9704 - val_loss: 0.6664 - val_accuracy: 0.8970\n",
      "Epoch 26/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.6835 - val_accuracy: 0.8977\n",
      "Epoch 27/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.0851 - accuracy: 0.9726 - val_loss: 0.7038 - val_accuracy: 0.8969\n",
      "Epoch 28/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.0815 - accuracy: 0.9739 - val_loss: 0.7302 - val_accuracy: 0.8952\n",
      "Epoch 29/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.0780 - accuracy: 0.9746 - val_loss: 0.7338 - val_accuracy: 0.8968\n",
      "Epoch 30/30\n",
      "4358/4358 [==============================] - 31s 7ms/step - loss: 0.0752 - accuracy: 0.9752 - val_loss: 0.7511 - val_accuracy: 0.8966\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_inputs3, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3=model.predict(test_inputs3)\n",
    "pred3=tf.argmax(pred3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=pred3\n",
    "sample_submission.to_csv('불용어 okt 패딩 40.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mecab 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_m1=[]\n",
    "temp_m2=[]\n",
    "for i in range(0,len(train2[['과제명']])):\n",
    "    temp_m1.append(mecab.nouns(str(train2.iloc[i])))\n",
    "for i in range(0,len(test2[['과제명']])):\n",
    "    temp_m2.append(mecab.nouns(str(test2.iloc[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(temp_m1)\n",
    "tokenizer.fit_on_texts(temp_m2)\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(temp_m1)\n",
    "test_sequences=tokenizer.texts_to_sequences(temp_m2)\n",
    "word_vocab=tokenizer.word_index\n",
    "\n",
    "train_inputs6=pad_sequences(train_sequences, maxlen=40, padding='post')\n",
    "test_inputs6=pad_sequences(test_sequences, maxlen=40, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 40, 32)            852768    \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 862,926\n",
      "Trainable params: 862,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 40\n",
    "oov_tok = \"<OOV>\"\n",
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.9234 - accuracy: 0.8206 - val_loss: 0.8035 - val_accuracy: 0.8248\n",
      "Epoch 2/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.6638 - accuracy: 0.8412 - val_loss: 0.6301 - val_accuracy: 0.8483\n",
      "Epoch 3/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.5247 - accuracy: 0.8639 - val_loss: 0.5517 - val_accuracy: 0.8607\n",
      "Epoch 4/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.4435 - accuracy: 0.8786 - val_loss: 0.5114 - val_accuracy: 0.8682\n",
      "Epoch 5/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.3842 - accuracy: 0.8920 - val_loss: 0.4864 - val_accuracy: 0.8761\n",
      "Epoch 6/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.3403 - accuracy: 0.9028 - val_loss: 0.4734 - val_accuracy: 0.8795\n",
      "Epoch 7/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.3068 - accuracy: 0.9105 - val_loss: 0.4806 - val_accuracy: 0.8737\n",
      "Epoch 8/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.2804 - accuracy: 0.9171 - val_loss: 0.4650 - val_accuracy: 0.8832\n",
      "Epoch 9/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.2599 - accuracy: 0.9225 - val_loss: 0.4649 - val_accuracy: 0.8859\n",
      "Epoch 10/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.2420 - accuracy: 0.9278 - val_loss: 0.4690 - val_accuracy: 0.8871\n",
      "Epoch 11/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.2267 - accuracy: 0.9322 - val_loss: 0.4797 - val_accuracy: 0.8881\n",
      "Epoch 12/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.2134 - accuracy: 0.9350 - val_loss: 0.4823 - val_accuracy: 0.8907\n",
      "Epoch 13/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.2013 - accuracy: 0.9390 - val_loss: 0.4904 - val_accuracy: 0.8891\n",
      "Epoch 14/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1906 - accuracy: 0.9418 - val_loss: 0.4923 - val_accuracy: 0.8920\n",
      "Epoch 15/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1801 - accuracy: 0.9444 - val_loss: 0.5094 - val_accuracy: 0.8924\n",
      "Epoch 16/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1707 - accuracy: 0.9473 - val_loss: 0.5261 - val_accuracy: 0.8945\n",
      "Epoch 17/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1622 - accuracy: 0.9500 - val_loss: 0.5296 - val_accuracy: 0.8917\n",
      "Epoch 18/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1535 - accuracy: 0.9526 - val_loss: 0.5422 - val_accuracy: 0.8927\n",
      "Epoch 19/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1466 - accuracy: 0.9547 - val_loss: 0.5469 - val_accuracy: 0.8929\n",
      "Epoch 20/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.1395 - accuracy: 0.9566 - val_loss: 0.5565 - val_accuracy: 0.8956\n",
      "Epoch 21/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1336 - accuracy: 0.9585 - val_loss: 0.5770 - val_accuracy: 0.8981\n",
      "Epoch 22/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.1269 - accuracy: 0.9607 - val_loss: 0.5839 - val_accuracy: 0.8936\n",
      "Epoch 23/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1211 - accuracy: 0.9619 - val_loss: 0.6024 - val_accuracy: 0.8973\n",
      "Epoch 24/30\n",
      "4358/4358 [==============================] - 27s 6ms/step - loss: 0.1154 - accuracy: 0.9634 - val_loss: 0.6115 - val_accuracy: 0.8940\n",
      "Epoch 25/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.1103 - accuracy: 0.9650 - val_loss: 0.6330 - val_accuracy: 0.8973\n",
      "Epoch 26/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.1061 - accuracy: 0.9665 - val_loss: 0.6358 - val_accuracy: 0.8952\n",
      "Epoch 27/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.1004 - accuracy: 0.9683 - val_loss: 0.6591 - val_accuracy: 0.8979\n",
      "Epoch 28/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.0975 - accuracy: 0.9689 - val_loss: 0.6635 - val_accuracy: 0.8964\n",
      "Epoch 29/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.0933 - accuracy: 0.9705 - val_loss: 0.6796 - val_accuracy: 0.8955\n",
      "Epoch 30/30\n",
      "4358/4358 [==============================] - 26s 6ms/step - loss: 0.0895 - accuracy: 0.9711 - val_loss: 0.6959 - val_accuracy: 0.8978\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_inputs6, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred6=model.predict(test_inputs6)\n",
    "pred6=tf.argmax(pred6, axis=1)\n",
    "sample_submission['label']=pred6\n",
    "sample_submission.to_csv('mecab 명사.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mecab 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, mecab, remove_stopwords=False, stop_words=[]):\n",
    "    text=re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ]\",\"\", text)\n",
    "    word_text=okt.morphs(text, stem=True)\n",
    "    if remove_stopwords:\n",
    "        word_text=[token for token in word_text if not token in stop_words]\n",
    "    return word_text\n",
    "\n",
    "stop_words=list(stop_w)\n",
    "clean_train_text=[]\n",
    "clean_test_text=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 174304/174304 [1:03:51<00:00, 45.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#시간이 많이 걸립니다.\n",
    "for text in tqdm.tqdm(train['과제명']):\n",
    "    try:\n",
    "        clean_train_text.append(preprocessing(text, mecab, remove_stopwords=True, stop_words=stop_words))\n",
    "    except:\n",
    "        clean_train_text.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 43576/43576 [31:03<00:00, 23.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm.tqdm(test['과제명']):\n",
    "    if type(text) == str:\n",
    "        clean_test_text.append(preprocessing(text, mecab, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        clean_test_text.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_text)\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(clean_train_text)\n",
    "test_sequences=tokenizer.texts_to_sequences(clean_test_text)\n",
    "word_vocab=tokenizer.word_index\n",
    "\n",
    "#패딩 처리\n",
    "train_inputs7=pad_sequences(train_sequences, maxlen=40, padding='post')\n",
    "test_inputs7=pad_sequences(test_sequences, maxlen=40, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 40, 32)            969152    \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 979,310\n",
      "Trainable params: 979,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "labels=np.array(train['label'])\n",
    "len(set(labels))\n",
    "\n",
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 40\n",
    "oov_tok = \"<OOV>\"\n",
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.9244 - accuracy: 0.8207 - val_loss: 0.8014 - val_accuracy: 0.8238\n",
      "Epoch 2/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.6791 - accuracy: 0.8369 - val_loss: 0.6494 - val_accuracy: 0.8442\n",
      "Epoch 3/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.5389 - accuracy: 0.8617 - val_loss: 0.5681 - val_accuracy: 0.8557\n",
      "Epoch 4/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.4445 - accuracy: 0.8800 - val_loss: 0.5184 - val_accuracy: 0.8668\n",
      "Epoch 5/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.3772 - accuracy: 0.8937 - val_loss: 0.4926 - val_accuracy: 0.8734\n",
      "Epoch 6/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.3277 - accuracy: 0.9055 - val_loss: 0.4833 - val_accuracy: 0.8790\n",
      "Epoch 7/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.2923 - accuracy: 0.9148 - val_loss: 0.4730 - val_accuracy: 0.8821\n",
      "Epoch 8/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.2645 - accuracy: 0.9214 - val_loss: 0.4772 - val_accuracy: 0.8837\n",
      "Epoch 9/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.2413 - accuracy: 0.9278 - val_loss: 0.4778 - val_accuracy: 0.8872\n",
      "Epoch 10/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.2225 - accuracy: 0.9329 - val_loss: 0.4961 - val_accuracy: 0.8888\n",
      "Epoch 11/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.2059 - accuracy: 0.9375 - val_loss: 0.4943 - val_accuracy: 0.8921\n",
      "Epoch 12/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1915 - accuracy: 0.9414 - val_loss: 0.5096 - val_accuracy: 0.8917\n",
      "Epoch 13/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1792 - accuracy: 0.9446 - val_loss: 0.5107 - val_accuracy: 0.8922\n",
      "Epoch 14/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1675 - accuracy: 0.9483 - val_loss: 0.5297 - val_accuracy: 0.8880\n",
      "Epoch 15/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1574 - accuracy: 0.9515 - val_loss: 0.5387 - val_accuracy: 0.8962\n",
      "Epoch 16/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1477 - accuracy: 0.9543 - val_loss: 0.5386 - val_accuracy: 0.8954\n",
      "Epoch 17/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1394 - accuracy: 0.9568 - val_loss: 0.5761 - val_accuracy: 0.8892\n",
      "Epoch 18/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1317 - accuracy: 0.9590 - val_loss: 0.5749 - val_accuracy: 0.8948\n",
      "Epoch 19/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1250 - accuracy: 0.9605 - val_loss: 0.5892 - val_accuracy: 0.8952\n",
      "Epoch 20/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1183 - accuracy: 0.9631 - val_loss: 0.5906 - val_accuracy: 0.8945\n",
      "Epoch 21/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1125 - accuracy: 0.9647 - val_loss: 0.6213 - val_accuracy: 0.8981\n",
      "Epoch 22/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1071 - accuracy: 0.9664 - val_loss: 0.6311 - val_accuracy: 0.8952\n",
      "Epoch 23/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.1017 - accuracy: 0.9677 - val_loss: 0.6376 - val_accuracy: 0.8950\n",
      "Epoch 24/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.0977 - accuracy: 0.9690 - val_loss: 0.6539 - val_accuracy: 0.8964\n",
      "Epoch 25/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.0924 - accuracy: 0.9706 - val_loss: 0.6890 - val_accuracy: 0.8917\n",
      "Epoch 26/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.0891 - accuracy: 0.9714 - val_loss: 0.6951 - val_accuracy: 0.8943\n",
      "Epoch 27/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.0856 - accuracy: 0.9726 - val_loss: 0.7011 - val_accuracy: 0.8983\n",
      "Epoch 28/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.0815 - accuracy: 0.9736 - val_loss: 0.7163 - val_accuracy: 0.8986\n",
      "Epoch 29/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.0786 - accuracy: 0.9744 - val_loss: 0.7440 - val_accuracy: 0.8925\n",
      "Epoch 30/30\n",
      "4358/4358 [==============================] - 28s 6ms/step - loss: 0.0757 - accuracy: 0.9754 - val_loss: 0.7584 - val_accuracy: 0.8948\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_inputs7, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred7=model.predict(test_inputs7)\n",
    "pred7=tf.argmax(pred7, axis=1)\n",
    "sample_submission['label']=pred7\n",
    "sample_submission.to_csv('mecab 형태소 불용어.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########################## 아래는 아니에요 ###########################\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 400\n",
    "oov_tok = \"<OOV>\"\n",
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs4=pad_sequences(train_sequences, maxlen=400, padding='post')\n",
    "test_inputs4=pad_sequences(test_sequences, maxlen=400, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_inputs4, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4=model.predict(test_inputs4)\n",
    "pred4=tf.argmax(pred4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=pred4\n",
    "sample_submission.to_csv('패딩400 okt 형태소2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_w=pd.read_csv(\"stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, okt, remove_stopwords=False, stop_words=[]):\n",
    "    text=re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ0-9]\",\"\", text)\n",
    "    word_text=okt.morphs(text, stem=True)\n",
    "    if remove_stopwords:\n",
    "        word_text=[token for token in word_text if not token in stop_words]\n",
    "    return word_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=list(stop_w)\n",
    "okt=Okt()\n",
    "clean_train_text2=[]\n",
    "clean_test_text2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 174304/174304 [5:36:08<00:00,  8.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#시간이 많이 걸립니다.\n",
    "for text in tqdm.tqdm(train['과제명']):\n",
    "    try:\n",
    "        clean_train_text2.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    except:\n",
    "        clean_train_text2.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 43576/43576 [1:28:13<00:00,  8.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm.tqdm(test['과제명']):\n",
    "    if type(text) == str:\n",
    "        clean_test_text2.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        clean_test_text2.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_text2)\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(clean_train_text2)\n",
    "test_sequences=tokenizer.texts_to_sequences(clean_test_text2)\n",
    "word_vocab=tokenizer.word_index\n",
    "\n",
    "#패딩 처리\n",
    "train_inputs5=pad_sequences(train_sequences, maxlen=40, padding='post')\n",
    "test_inputs5=pad_sequences(test_sequences, maxlen=40, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array(train['label'])\n",
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43576, 40)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 40, 32)            1383872   \n",
      "                                                                 \n",
      " global_average_pooling1d_7   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,030\n",
      "Trainable params: 1,394,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 40\n",
    "oov_tok = \"<OOV>\"\n",
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4585/4589 [============================>.] - ETA: 0s - loss: 1.0960 - accuracy: 0.8181"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 36708\n  y sizes: 27475\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-93b24ecde104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(train_inputs5, labels, \n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     validation_split=0.2)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[0;32m   1656\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 36708\n  y sizes: 27475\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_inputs5, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5=model.predict(test_inputs5)\n",
    "pred5=tf.argmax(pred5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=pred5\n",
    "sample_submission.to_csv('패딩40 okt 불용어.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#패딩 처리\n",
    "train_inputs6=pad_sequences(train_sequences, maxlen=400, padding='post')\n",
    "test_inputs6=pad_sequences(test_sequences, maxlen=400, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array(train['label'])\n",
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 400, 32)           1383872   \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,030\n",
      "Trainable params: 1,394,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#파라미터 설정\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 32\n",
    "max_length = 400\n",
    "oov_tok = \"<OOV>\"\n",
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4586/4589 [============================>.] - ETA: 0s - loss: 1.0925 - accuracy: 0.8180"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 36708\n  y sizes: 27475\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-01a0e6d2c4ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(train_inputs6, labels, \n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     validation_split=0.2)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[0;32m   1656\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 36708\n  y sizes: 27475\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_inputs6, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred6=model.predict(test_inputs6)\n",
    "pred6=tf.argmax(pred6, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=pred6\n",
    "sample_submission.to_csv('패딩400 okt 불용어.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_data=list()\n",
    "for i in range(0,len(stop_w)):\n",
    "    stop_data.append(sw[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['휴'],\n",
       " ['아이구'],\n",
       " ['아이쿠'],\n",
       " ['아이고'],\n",
       " ['어'],\n",
       " ['나'],\n",
       " ['우리'],\n",
       " ['저희'],\n",
       " ['따라'],\n",
       " ['의해'],\n",
       " ['을'],\n",
       " ['를'],\n",
       " ['에'],\n",
       " ['의'],\n",
       " ['가'],\n",
       " ['으로'],\n",
       " ['로'],\n",
       " ['에게'],\n",
       " ['뿐이다'],\n",
       " ['의거하여'],\n",
       " ['근거하여'],\n",
       " ['입각하여'],\n",
       " ['기준으로'],\n",
       " ['예하면'],\n",
       " ['예를 들면'],\n",
       " ['예를 들자면'],\n",
       " ['저'],\n",
       " ['소인'],\n",
       " ['소생'],\n",
       " ['저희'],\n",
       " ['지말고'],\n",
       " ['하지마'],\n",
       " ['하지마라'],\n",
       " ['다른'],\n",
       " ['물론'],\n",
       " ['또한'],\n",
       " ['그리고'],\n",
       " ['비길수 없다'],\n",
       " ['해서는 안된다'],\n",
       " ['뿐만 아니라'],\n",
       " ['만이 아니다'],\n",
       " ['만은 아니다'],\n",
       " ['막론하고'],\n",
       " ['관계없이'],\n",
       " ['그치지 않다'],\n",
       " ['그러나'],\n",
       " ['그런데'],\n",
       " ['하지만'],\n",
       " ['든간에'],\n",
       " ['논하지 않다'],\n",
       " ['따지지 않다'],\n",
       " ['설사'],\n",
       " ['비록'],\n",
       " ['더라도'],\n",
       " ['아니면'],\n",
       " ['만 못하다'],\n",
       " ['하는 편이 낫다'],\n",
       " ['불문하고'],\n",
       " ['향하여'],\n",
       " ['향해서'],\n",
       " ['향하다'],\n",
       " ['쪽으로'],\n",
       " ['틈타'],\n",
       " ['이용하여'],\n",
       " ['타다'],\n",
       " ['오르다'],\n",
       " ['제외하고'],\n",
       " ['이 외에'],\n",
       " ['이 밖에'],\n",
       " ['하여야'],\n",
       " ['비로소'],\n",
       " ['한다면 몰라도'],\n",
       " ['외에도'],\n",
       " ['이곳'],\n",
       " ['여기'],\n",
       " ['부터'],\n",
       " ['기점으로'],\n",
       " ['따라서'],\n",
       " ['할 생각이다'],\n",
       " ['하려고하다'],\n",
       " ['이리하여'],\n",
       " ['그리하여'],\n",
       " ['그렇게 함으로써'],\n",
       " ['하지만'],\n",
       " ['일때'],\n",
       " ['할때'],\n",
       " ['앞에서'],\n",
       " ['중에서'],\n",
       " ['보는데서'],\n",
       " ['으로써'],\n",
       " ['로써'],\n",
       " ['까지'],\n",
       " ['해야한다'],\n",
       " ['일것이다'],\n",
       " ['반드시'],\n",
       " ['할줄알다'],\n",
       " ['할수있다'],\n",
       " ['할수있어'],\n",
       " ['임에 틀림없다'],\n",
       " ['한다면'],\n",
       " ['등'],\n",
       " ['등등'],\n",
       " ['제'],\n",
       " ['겨우'],\n",
       " ['단지'],\n",
       " ['다만'],\n",
       " ['할뿐'],\n",
       " ['딩동'],\n",
       " ['댕그'],\n",
       " ['대해서'],\n",
       " ['대하여'],\n",
       " ['대하면'],\n",
       " ['훨씬'],\n",
       " ['얼마나'],\n",
       " ['얼마만큼'],\n",
       " ['얼마큼'],\n",
       " ['남짓'],\n",
       " ['여'],\n",
       " ['얼마간'],\n",
       " ['약간'],\n",
       " ['다소'],\n",
       " ['좀'],\n",
       " ['조금'],\n",
       " ['다수'],\n",
       " ['몇'],\n",
       " ['얼마'],\n",
       " ['지만'],\n",
       " ['하물며'],\n",
       " ['또한'],\n",
       " ['그러나'],\n",
       " ['그렇지만'],\n",
       " ['하지만'],\n",
       " ['이외에도'],\n",
       " ['대해 말하자면'],\n",
       " ['뿐이다'],\n",
       " ['다음에'],\n",
       " ['반대로'],\n",
       " ['반대로 말하자면'],\n",
       " ['이와 반대로'],\n",
       " ['바꾸어서 말하면'],\n",
       " ['바꾸어서 한다면'],\n",
       " ['만약'],\n",
       " ['그렇지않으면'],\n",
       " ['까악'],\n",
       " ['툭'],\n",
       " ['딱'],\n",
       " ['삐걱거리다'],\n",
       " ['보드득'],\n",
       " ['비걱거리다'],\n",
       " ['꽈당'],\n",
       " ['응당'],\n",
       " ['해야한다'],\n",
       " ['에 가서'],\n",
       " ['각'],\n",
       " ['각각'],\n",
       " ['여러분'],\n",
       " ['각종'],\n",
       " ['각자'],\n",
       " ['제각기'],\n",
       " ['하도록하다'],\n",
       " ['와'],\n",
       " ['과'],\n",
       " ['그러므로'],\n",
       " ['그래서'],\n",
       " ['고로'],\n",
       " ['한 까닭에'],\n",
       " ['하기 때문에'],\n",
       " ['거니와'],\n",
       " ['이지만'],\n",
       " ['대하여'],\n",
       " ['관하여'],\n",
       " ['관한'],\n",
       " ['과연'],\n",
       " ['실로'],\n",
       " ['아니나다를가'],\n",
       " ['생각한대로'],\n",
       " ['진짜로'],\n",
       " ['한적이있다'],\n",
       " ['하곤하였다'],\n",
       " ['하'],\n",
       " ['하하'],\n",
       " ['허허'],\n",
       " ['아하'],\n",
       " ['거바'],\n",
       " ['와'],\n",
       " ['오'],\n",
       " ['왜'],\n",
       " ['어째서'],\n",
       " ['무엇때문에'],\n",
       " ['어찌'],\n",
       " ['하겠는가'],\n",
       " ['무슨'],\n",
       " ['어디'],\n",
       " ['어느곳'],\n",
       " ['더군다나'],\n",
       " ['하물며'],\n",
       " ['더욱이는'],\n",
       " ['어느때'],\n",
       " ['언제'],\n",
       " ['야'],\n",
       " ['이봐'],\n",
       " ['어이'],\n",
       " ['여보시오'],\n",
       " ['흐흐'],\n",
       " ['흥'],\n",
       " ['휴'],\n",
       " ['헉헉'],\n",
       " ['헐떡헐떡'],\n",
       " ['영차'],\n",
       " ['여차'],\n",
       " ['어기여차'],\n",
       " ['끙끙'],\n",
       " ['아야'],\n",
       " ['앗'],\n",
       " ['아야'],\n",
       " ['콸콸'],\n",
       " ['졸졸'],\n",
       " ['좍좍'],\n",
       " ['뚝뚝'],\n",
       " ['주룩주룩'],\n",
       " ['솨'],\n",
       " ['우르르'],\n",
       " ['그래도'],\n",
       " ['또'],\n",
       " ['그리고'],\n",
       " ['바꾸어말하면'],\n",
       " ['바꾸어말하자면'],\n",
       " ['혹은'],\n",
       " ['혹시'],\n",
       " ['답다'],\n",
       " ['및'],\n",
       " ['그에 따르는'],\n",
       " ['때가 되어'],\n",
       " ['즉'],\n",
       " ['지든지'],\n",
       " ['설령'],\n",
       " ['가령'],\n",
       " ['하더라도'],\n",
       " ['할지라도'],\n",
       " ['일지라도'],\n",
       " ['지든지'],\n",
       " ['몇'],\n",
       " ['거의'],\n",
       " ['하마터면'],\n",
       " ['인젠'],\n",
       " ['이젠'],\n",
       " ['된바에야'],\n",
       " ['된이상'],\n",
       " ['만큼'],\n",
       " ['그위에'],\n",
       " ['게다가'],\n",
       " ['점에서 보아'],\n",
       " ['비추어 보아'],\n",
       " ['고려하면'],\n",
       " ['하게될것이다'],\n",
       " ['일것이다'],\n",
       " ['비교적'],\n",
       " ['좀'],\n",
       " ['보다더'],\n",
       " ['비하면'],\n",
       " ['시키다'],\n",
       " ['하게하다'],\n",
       " ['할만하다'],\n",
       " ['의해서'],\n",
       " ['연이서'],\n",
       " ['이어서'],\n",
       " ['잇따라'],\n",
       " ['뒤따라'],\n",
       " ['뒤이어'],\n",
       " ['결국'],\n",
       " ['의지하여'],\n",
       " ['기대여'],\n",
       " ['통하여'],\n",
       " ['자마자'],\n",
       " ['더욱더'],\n",
       " ['불구하고'],\n",
       " ['얼마든지'],\n",
       " ['마음대로'],\n",
       " ['주저하지 않고'],\n",
       " ['곧'],\n",
       " ['즉시'],\n",
       " ['바로'],\n",
       " ['당장'],\n",
       " ['하자마자'],\n",
       " ['밖에 안된다'],\n",
       " ['하면된다'],\n",
       " ['그래'],\n",
       " ['그렇지'],\n",
       " ['요컨대'],\n",
       " ['다시 말하자면'],\n",
       " ['바꿔 말하면'],\n",
       " ['즉'],\n",
       " ['구체적으로'],\n",
       " ['말하자면'],\n",
       " ['시작하여'],\n",
       " ['시초에'],\n",
       " ['이상'],\n",
       " ['허'],\n",
       " ['헉'],\n",
       " ['허걱'],\n",
       " ['바와같이'],\n",
       " ['해도좋다'],\n",
       " ['해도된다'],\n",
       " ['게다가'],\n",
       " ['더구나'],\n",
       " ['하물며'],\n",
       " ['와르르'],\n",
       " ['팍'],\n",
       " ['퍽'],\n",
       " ['펄렁'],\n",
       " ['동안'],\n",
       " ['이래'],\n",
       " ['하고있었다'],\n",
       " ['이었다'],\n",
       " ['에서'],\n",
       " ['로부터'],\n",
       " ['까지'],\n",
       " ['예하면'],\n",
       " ['했어요'],\n",
       " ['해요'],\n",
       " ['함께'],\n",
       " ['같이'],\n",
       " ['더불어'],\n",
       " ['마저'],\n",
       " ['마저도'],\n",
       " ['양자'],\n",
       " ['모두'],\n",
       " ['습니다'],\n",
       " ['가까스로'],\n",
       " ['하려고하다'],\n",
       " ['즈음하여'],\n",
       " ['다른'],\n",
       " ['다른 방면으로'],\n",
       " ['해봐요'],\n",
       " ['습니까'],\n",
       " ['했어요'],\n",
       " ['말할것도 없고'],\n",
       " ['무릎쓰고'],\n",
       " ['개의치않고'],\n",
       " ['하는것만 못하다'],\n",
       " ['하는것이 낫다'],\n",
       " ['매'],\n",
       " ['매번'],\n",
       " ['들'],\n",
       " ['모'],\n",
       " ['어느것'],\n",
       " ['어느'],\n",
       " ['로써'],\n",
       " ['갖고말하자면'],\n",
       " ['어디'],\n",
       " ['어느쪽'],\n",
       " ['어느것'],\n",
       " ['어느해'],\n",
       " ['어느 년도'],\n",
       " ['라 해도'],\n",
       " ['언젠가'],\n",
       " ['어떤것'],\n",
       " ['어느것'],\n",
       " ['저기'],\n",
       " ['저쪽'],\n",
       " ['저것'],\n",
       " ['그때'],\n",
       " ['그럼'],\n",
       " ['그러면'],\n",
       " ['요만한걸'],\n",
       " ['그래'],\n",
       " ['그때'],\n",
       " ['저것만큼'],\n",
       " ['그저'],\n",
       " ['이르기까지'],\n",
       " ['할 줄 안다'],\n",
       " ['할 힘이 있다'],\n",
       " ['너'],\n",
       " ['너희'],\n",
       " ['당신'],\n",
       " ['어찌'],\n",
       " ['설마'],\n",
       " ['차라리'],\n",
       " ['할지언정'],\n",
       " ['할지라도'],\n",
       " ['할망정'],\n",
       " ['할지언정'],\n",
       " ['구토하다'],\n",
       " ['게우다'],\n",
       " ['토하다'],\n",
       " ['메쓰겁다'],\n",
       " ['옆사람'],\n",
       " ['퉤'],\n",
       " ['쳇'],\n",
       " ['의거하여'],\n",
       " ['근거하여'],\n",
       " ['의해'],\n",
       " ['따라'],\n",
       " ['힘입어'],\n",
       " ['그'],\n",
       " ['다음'],\n",
       " ['버금'],\n",
       " ['두번째로'],\n",
       " ['기타'],\n",
       " ['첫번째로'],\n",
       " ['나머지는'],\n",
       " ['그중에서'],\n",
       " ['견지에서'],\n",
       " ['형식으로 쓰여'],\n",
       " ['입장에서'],\n",
       " ['위해서'],\n",
       " ['단지'],\n",
       " ['의해되다'],\n",
       " ['하도록시키다'],\n",
       " ['뿐만아니라'],\n",
       " ['반대로'],\n",
       " ['전후'],\n",
       " ['전자'],\n",
       " ['앞의것'],\n",
       " ['잠시'],\n",
       " ['잠깐'],\n",
       " ['하면서'],\n",
       " ['그렇지만'],\n",
       " ['다음에'],\n",
       " ['그러한즉'],\n",
       " ['그런즉'],\n",
       " ['남들'],\n",
       " ['아무거나'],\n",
       " ['어찌하든지'],\n",
       " ['같다'],\n",
       " ['비슷하다'],\n",
       " ['예컨대'],\n",
       " ['이럴정도로'],\n",
       " ['어떻게'],\n",
       " ['만약'],\n",
       " ['만일'],\n",
       " ['위에서 서술한바와같이'],\n",
       " ['인 듯하다'],\n",
       " ['하지 않는다면'],\n",
       " ['만약에'],\n",
       " ['무엇'],\n",
       " ['무슨'],\n",
       " ['어느'],\n",
       " ['어떤'],\n",
       " ['아래윗'],\n",
       " ['조차'],\n",
       " ['한데'],\n",
       " ['그럼에도 불구하고'],\n",
       " ['여전히'],\n",
       " ['심지어'],\n",
       " ['까지도'],\n",
       " ['조차도'],\n",
       " ['하지 않도록'],\n",
       " ['않기 위하여'],\n",
       " ['때'],\n",
       " ['시각'],\n",
       " ['무렵'],\n",
       " ['시간'],\n",
       " ['동안'],\n",
       " ['어때'],\n",
       " ['어떠한'],\n",
       " ['하여금'],\n",
       " ['네'],\n",
       " ['예'],\n",
       " ['우선'],\n",
       " ['누구'],\n",
       " ['누가 알겠는가'],\n",
       " ['아무도'],\n",
       " ['줄은모른다'],\n",
       " ['줄은 몰랏다'],\n",
       " ['하는 김에'],\n",
       " ['겸사겸사'],\n",
       " ['하는바'],\n",
       " ['그런 까닭에'],\n",
       " ['한 이유는'],\n",
       " ['그러니'],\n",
       " ['그러니까'],\n",
       " ['때문에'],\n",
       " ['그'],\n",
       " ['너희'],\n",
       " ['그들'],\n",
       " ['너희들'],\n",
       " ['타인'],\n",
       " ['것'],\n",
       " ['것들'],\n",
       " ['너'],\n",
       " ['위하여'],\n",
       " ['공동으로'],\n",
       " ['동시에'],\n",
       " ['하기 위하여'],\n",
       " ['어찌하여'],\n",
       " ['무엇때문에'],\n",
       " ['붕붕'],\n",
       " ['윙윙'],\n",
       " ['나'],\n",
       " ['우리'],\n",
       " ['엉엉'],\n",
       " ['휘익'],\n",
       " ['윙윙'],\n",
       " ['오호'],\n",
       " ['아하'],\n",
       " ['어쨋든'],\n",
       " ['만 못하다'],\n",
       " ['차라리'],\n",
       " ['하는 편이 낫다'],\n",
       " ['흐흐'],\n",
       " ['놀라다'],\n",
       " ['상대적으로 말하자면'],\n",
       " ['마치'],\n",
       " ['아니라면'],\n",
       " ['쉿'],\n",
       " ['그렇지 않으면'],\n",
       " ['그렇지 않다면'],\n",
       " ['안 그러면'],\n",
       " ['아니었다면'],\n",
       " ['하든지'],\n",
       " ['아니면'],\n",
       " ['이라면'],\n",
       " ['좋아'],\n",
       " ['알았어'],\n",
       " ['하는것도'],\n",
       " ['그만이다'],\n",
       " ['어쩔수 없다'],\n",
       " ['하나'],\n",
       " ['일'],\n",
       " ['일반적으로'],\n",
       " ['일단'],\n",
       " ['한켠으로는'],\n",
       " ['오자마자'],\n",
       " ['이렇게되면'],\n",
       " ['이와같다면'],\n",
       " ['전부'],\n",
       " ['한마디'],\n",
       " ['한항목'],\n",
       " ['근거로'],\n",
       " ['하기에'],\n",
       " ['아울러'],\n",
       " ['하지 않도록'],\n",
       " ['않기 위해서'],\n",
       " ['이르기까지'],\n",
       " ['이 되다'],\n",
       " ['로 인하여'],\n",
       " ['까닭으로'],\n",
       " ['이유만으로'],\n",
       " ['이로 인하여'],\n",
       " ['그래서'],\n",
       " ['이 때문에'],\n",
       " ['그러므로'],\n",
       " ['그런 까닭에'],\n",
       " ['알 수 있다'],\n",
       " ['결론을 낼 수 있다'],\n",
       " ['으로 인하여'],\n",
       " ['있다'],\n",
       " ['어떤것'],\n",
       " ['관계가 있다'],\n",
       " ['관련이 있다'],\n",
       " ['연관되다'],\n",
       " ['어떤것들'],\n",
       " ['에 대해'],\n",
       " ['이리하여'],\n",
       " ['그리하여'],\n",
       " ['여부'],\n",
       " ['하기보다는'],\n",
       " ['하느니'],\n",
       " ['하면 할수록'],\n",
       " ['운운'],\n",
       " ['이러이러하다'],\n",
       " ['하구나'],\n",
       " ['하도다'],\n",
       " ['다시말하면'],\n",
       " ['다음으로'],\n",
       " ['에 있다'],\n",
       " ['에 달려 있다'],\n",
       " ['우리'],\n",
       " ['우리들'],\n",
       " ['오히려'],\n",
       " ['하기는한데'],\n",
       " ['어떻게'],\n",
       " ['어떻해'],\n",
       " ['어찌됏어'],\n",
       " ['어때'],\n",
       " ['어째서'],\n",
       " ['본대로'],\n",
       " ['자'],\n",
       " ['이'],\n",
       " ['이쪽'],\n",
       " ['여기'],\n",
       " ['이것'],\n",
       " ['이번'],\n",
       " ['이렇게말하자면'],\n",
       " ['이런'],\n",
       " ['이러한'],\n",
       " ['이와 같은'],\n",
       " ['요만큼'],\n",
       " ['요만한 것'],\n",
       " ['얼마 안 되는 것'],\n",
       " ['이만큼'],\n",
       " ['이 정도의'],\n",
       " ['이렇게 많은 것'],\n",
       " ['이와 같다'],\n",
       " ['이때'],\n",
       " ['이렇구나'],\n",
       " ['것과 같이'],\n",
       " ['끼익'],\n",
       " ['삐걱'],\n",
       " ['따위'],\n",
       " ['와 같은 사람들'],\n",
       " ['부류의 사람들'],\n",
       " ['왜냐하면'],\n",
       " ['중의하나'],\n",
       " ['오직'],\n",
       " ['오로지'],\n",
       " ['에 한하다'],\n",
       " ['하기만 하면'],\n",
       " ['도착하다'],\n",
       " ['까지 미치다'],\n",
       " ['도달하다'],\n",
       " ['정도에 이르다'],\n",
       " ['할 지경이다'],\n",
       " ['결과에 이르다'],\n",
       " ['관해서는'],\n",
       " ['여러분'],\n",
       " ['하고 있다'],\n",
       " ['한 후'],\n",
       " ['혼자'],\n",
       " ['자기'],\n",
       " ['자기집'],\n",
       " ['자신'],\n",
       " ['우에 종합한것과같이'],\n",
       " ['총적으로 보면'],\n",
       " ['총적으로 말하면'],\n",
       " ['총적으로'],\n",
       " ['대로 하다'],\n",
       " ['으로서'],\n",
       " ['참'],\n",
       " ['그만이다'],\n",
       " ['할 따름이다'],\n",
       " ['쿵'],\n",
       " ['탕탕'],\n",
       " ['쾅쾅'],\n",
       " ['둥둥'],\n",
       " ['봐'],\n",
       " ['봐라'],\n",
       " ['아이야'],\n",
       " ['아니'],\n",
       " ['와아'],\n",
       " ['응'],\n",
       " ['아이'],\n",
       " ['참나'],\n",
       " ['년'],\n",
       " ['월'],\n",
       " ['일'],\n",
       " ['령'],\n",
       " ['영'],\n",
       " ['일'],\n",
       " ['이'],\n",
       " ['삼'],\n",
       " ['사'],\n",
       " ['오'],\n",
       " ['육'],\n",
       " ['륙'],\n",
       " ['칠'],\n",
       " ['팔'],\n",
       " ['구'],\n",
       " ['이천육'],\n",
       " ['이천칠'],\n",
       " ['이천팔'],\n",
       " ['이천구'],\n",
       " ['하나'],\n",
       " ['둘'],\n",
       " ['셋'],\n",
       " ['넷'],\n",
       " ['다섯'],\n",
       " ['여섯'],\n",
       " ['일곱'],\n",
       " ['여덟'],\n",
       " ['아홉'],\n",
       " ['령'],\n",
       " ['영']]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(temp)\n",
    "tokenizer.fit_on_texts(temp2)\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(temp)\n",
    "test_sequences=tokenizer.texts_to_sequences(temp2)\n",
    "word_vocab=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs=pad_sequences(train_sequences, maxlen=40, padding='post')\n",
    "test_inputs=pad_sequences(test_sequences, maxlen=40, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = np.load('./data_in/train_input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, okt, remove_stopwords=False, stop_words=[]):\n",
    "    text=re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ]\",\"\", text)\n",
    "    word_text=okt.morphs(text, stem=True)\n",
    "    if remove_stopwords:\n",
    "        word_text=[token for token in word_text if not token in stop_words]\n",
    "    return word_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=['은','는','이','가', '하','아','것','들','의','있','되','수','보','주','등','한']\n",
    "okt=Okt()\n",
    "clean_train_text=[]\n",
    "clean_test_text=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시간이 많이 걸립니다.\n",
    "for text in tqdm.tqdm(train['과제명']):\n",
    "    try:\n",
    "        clean_train_text.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    except:\n",
    "        clean_train_text.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tqdm.tqdm(test['과제명']):\n",
    "    if type(text) == str:\n",
    "        clean_test_text.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        clean_test_text.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서플로의 전처리 모듈을 활용해 토크나이징 객체를 만든 후 인덱스 벡터로 전환\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_text)\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(clean_train_text)\n",
    "test_sequences=tokenizer.texts_to_sequences(clean_test_text)\n",
    "word_vocab=tokenizer.word_index\n",
    "\n",
    "#패딩 처리\n",
    "train_inputs=pad_sequences(train_sequences, maxlen=40, padding='post')\n",
    "test_inputs=pad_sequences(test_sequences, maxlen=40, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_inputs.shape)\n",
    "print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(train['label'])\n",
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추후 재사용 가능하도록 npy로 전환\n",
    "DATA_IN_PATH='./data_in/'\n",
    "TRAIN_INPUT_DATA = 'train_input.npy'\n",
    "TEST_INPUT_DATA = 'test_input.npy'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(DATA_IN_PATH):\n",
    "    os.makedirs(DATA_IN_PATH)\n",
    "    \n",
    "np.save(open(DATA_IN_PATH+TRAIN_INPUT_DATA, 'wb'), train_inputs)\n",
    "np.save(open(DATA_IN_PATH+TEST_INPUT_DATA, 'wb'), test_inputs)\n",
    "\n",
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)+1\n",
    "json.dump(data_configs, open(DATA_IN_PATH+'data_configs.json', 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "vocab_size =data_configs['vocab_size']\n",
    "embedding_dim = 64\n",
    "max_length = 40\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가벼운 NLP모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "num_epochs = 30\n",
    "history = model.fit(train_inputs, labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평가지표가 Macro F1이기에 확률값으로 결과를 내면 안됩니다.\n",
    "pred=model.predict(test_inputs)\n",
    "pred=tf.argmax(pred, axis=1)\n",
    "\n",
    "sample_submission['label']=pred\n",
    "\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('baseline4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포래스트\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#tokenizer 인자에는 list를 받아서 그대로 내보내는 함수를 넣어줍니다. 또한 소문자화를 하지 않도록 설정해야 에러가 나지 않습니다.\n",
    "vectorizer = CountVectorizer(tokenizer = lambda x: x, lowercase=False)\n",
    "train_features=vectorizer.fit_transform(clean_train_text)\n",
    "test_features=vectorizer.transform(clean_test_text)\n",
    "#test데이터에 fit_transform을 할 경우 data leakage에 해당합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 데이터 셋과 검증 데이터 셋으로 분리\n",
    "TEST_SIZE=0.2\n",
    "RANDOM_SEED=42\n",
    "\n",
    "train_x, eval_x, train_y, eval_y=train_test_split(train_features, train['label'], test_size=TEST_SIZE, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤포레스트로 모델링\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "forest.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 검증\n",
    "forest.score(eval_x, eval_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15608201088283213939\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- @ file:///C:/ci/importlib-metadata_1617877484576/work\n",
      "-mportlib-metadata @ file:///C:/ci/importlib-metadata_1617877484576/work\n",
      "absl-py==1.0.0\n",
      "alabaster @ file:///home/ktietz/src/ci/alabaster_1611921544520/work\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==2.0.3\n",
      "anaconda-project @ file:///tmp/build/80754af9/anaconda-project_1610472525955/work\n",
      "anyio @ file:///C:/ci/anyio_1620153418380/work/dist\n",
      "appdirs==1.4.4\n",
      "argh==0.26.2\n",
      "argon2-cffi @ file:///C:/ci/argon2-cffi_1613037959010/work\n",
      "asn1crypto @ file:///tmp/build/80754af9/asn1crypto_1596577642040/work\n",
      "astroid @ file:///C:/ci/astroid_1613501047216/work\n",
      "astropy @ file:///C:/ci/astropy_1617745647203/work\n",
      "astunparse==1.6.3\n",
      "async-generator @ file:///home/ktietz/src/ci/async_generator_1611927993394/work\n",
      "atomicwrites==1.4.0\n",
      "attrs @ file:///tmp/build/80754af9/attrs_1604765588209/work\n",
      "autopep8 @ file:///tmp/build/80754af9/autopep8_1615918855173/work\n",
      "Babel @ file:///tmp/build/80754af9/babel_1607110387436/work\n",
      "backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work\n",
      "backports.functools-lru-cache @ file:///tmp/build/80754af9/backports.functools_lru_cache_1618170165463/work\n",
      "backports.shutil-get-terminal-size @ file:///tmp/build/80754af9/backports.shutil_get_terminal_size_1608222128777/work\n",
      "backports.tempfile @ file:///home/linux1/recipes/ci/backports.tempfile_1610991236607/work\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt @ file:///C:/ci/bcrypt_1597936263757/work\n",
      "beautifulsoup4 @ file:///home/linux1/recipes/ci/beautifulsoup4_1610988766420/work\n",
      "bitarray @ file:///C:/ci/bitarray_1618435038389/work\n",
      "bkcharts==0.2\n",
      "black==19.10b0\n",
      "bleach @ file:///tmp/build/80754af9/bleach_1612211392645/work\n",
      "bokeh @ file:///C:/ci/bokeh_1620784067744/work\n",
      "boto==2.49.0\n",
      "Bottleneck==1.3.2\n",
      "brotlipy==0.7.0\n",
      "cachetools==4.2.4\n",
      "certifi==2020.12.5\n",
      "cffi @ file:///C:/ci/cffi_1613247279197/work\n",
      "chardet @ file:///C:/ci/chardet_1607690654534/work\n",
      "click @ file:///home/linux1/recipes/ci/click_1610990599742/work\n",
      "cloudpickle @ file:///tmp/build/80754af9/cloudpickle_1598884132938/work\n",
      "clyent==1.2.2\n",
      "colorama @ file:///tmp/build/80754af9/colorama_1607707115595/work\n",
      "comtypes==1.1.9\n",
      "conda==4.10.1\n",
      "conda-build==3.21.4\n",
      "conda-content-trust @ file:///tmp/build/80754af9/conda-content-trust_1617045594566/work\n",
      "conda-package-handling @ file:///C:/ci/conda-package-handling_1618262320430/work\n",
      "conda-repo-cli @ file:///tmp/build/80754af9/conda-repo-cli_1620168426516/work\n",
      "conda-token @ file:///tmp/build/80754af9/conda-token_1620076980546/work\n",
      "conda-verify==3.4.2\n",
      "contextlib2==0.6.0.post1\n",
      "cryptography @ file:///C:/ci/cryptography_1616769344312/work\n",
      "cycler==0.10.0\n",
      "Cython @ file:///C:/ci/cython_1618435363327/work\n",
      "cytoolz==0.11.0\n",
      "dask @ file:///tmp/build/80754af9/dask-core_1617390489108/work\n",
      "decorator @ file:///tmp/build/80754af9/decorator_1617916966915/work\n",
      "defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work\n",
      "diff-match-patch @ file:///tmp/build/80754af9/diff-match-patch_1594828741838/work\n",
      "distributed @ file:///C:/ci/distributed_1617384289923/work\n",
      "docutils @ file:///C:/ci/docutils_1617481617511/work\n",
      "emoji==1.6.1\n",
      "entrypoints==0.3\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.1.0\n",
      "filelock @ file:///home/linux1/recipes/ci/filelock_1610993975404/work\n",
      "flake8 @ file:///tmp/build/80754af9/flake8_1615834841867/work\n",
      "Flask @ file:///home/ktietz/src/ci/flask_1611932660458/work\n",
      "flatbuffers==2.0\n",
      "fsspec @ file:///tmp/build/80754af9/fsspec_1617959894824/work\n",
      "future==0.18.2\n",
      "gast==0.4.0\n",
      "gensim==4.1.2\n",
      "gevent @ file:///C:/ci/gevent_1616773090559/work\n",
      "glob2 @ file:///home/linux1/recipes/ci/glob2_1610991677669/work\n",
      "google-auth==2.3.3\n",
      "google-auth-oauthlib==0.4.6\n",
      "google-pasta==0.2.0\n",
      "greenlet @ file:///C:/ci/greenlet_1611958565931/work\n",
      "grpcio==1.43.0\n",
      "h5py==2.10.0\n",
      "HeapDict==1.0.1\n",
      "html5lib @ file:///tmp/build/80754af9/html5lib_1593446221756/work\n",
      "huggingface-hub==0.4.0\n",
      "idna @ file:///home/linux1/recipes/ci/idna_1610986105248/work\n",
      "imagecodecs @ file:///C:/ci/imagecodecs_1617996768495/work\n",
      "imageio @ file:///tmp/build/80754af9/imageio_1617700267927/work\n",
      "imagesize @ file:///home/ktietz/src/ci/imagesize_1611921604382/work\n",
      "importlib-metadata==4.10.0\n",
      "iniconfig @ file:///home/linux1/recipes/ci/iniconfig_1610983019677/work\n",
      "intervaltree @ file:///tmp/build/80754af9/intervaltree_1598376443606/work\n",
      "ipykernel @ file:///C:/ci/ipykernel_1596190155316/work/dist/ipykernel-5.3.4-py3-none-any.whl\n",
      "ipython @ file:///C:/ci/ipython_1617121002983/work\n",
      "ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work\n",
      "ipywidgets @ file:///tmp/build/80754af9/ipywidgets_1610481889018/work\n",
      "isort @ file:///tmp/build/80754af9/isort_1616355431277/work\n",
      "itsdangerous @ file:///home/ktietz/src/ci/itsdangerous_1611932585308/work\n",
      "jdcal==1.4.1\n",
      "jedi @ file:///C:/ci/jedi_1606914528444/work\n",
      "Jinja2 @ file:///tmp/build/80754af9/jinja2_1612213139570/work\n",
      "joblib @ file:///tmp/build/80754af9/joblib_1613502643832/work\n",
      "JPype1 @ file:///C:/Users/09eoe/Desktop/JPype1-1.3.0-cp38-cp38-win_amd64.whl\n",
      "json5==0.9.5\n",
      "jsonschema @ file:///tmp/build/80754af9/jsonschema_1602607155483/work\n",
      "jupyter==1.0.0\n",
      "jupyter-client @ file:///tmp/build/80754af9/jupyter_client_1616770841739/work\n",
      "jupyter-console @ file:///tmp/build/80754af9/jupyter_console_1616615302928/work\n",
      "jupyter-core @ file:///C:/ci/jupyter_core_1612213356021/work\n",
      "jupyter-packaging @ file:///tmp/build/80754af9/jupyter-packaging_1613502826984/work\n",
      "jupyter-server @ file:///C:/ci/jupyter_server_1616084298403/work\n",
      "jupyterlab @ file:///tmp/build/80754af9/jupyterlab_1619133235951/work\n",
      "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\n",
      "jupyterlab-server @ file:///tmp/build/80754af9/jupyterlab_server_1617134334258/work\n",
      "jupyterlab-widgets @ file:///tmp/build/80754af9/jupyterlab_widgets_1609884341231/workNote: you may need to restart the kernel to use updated packages.\n",
      "keras==2.7.0\n",
      "Keras-Preprocessing==1.1.2\n",
      "keyring @ file:///C:/ci/keyring_1614616910860/work\n",
      "kiwisolver @ file:///C:/ci/kiwisolver_1612282606037/work\n",
      "konlpy==0.6.0\n",
      "kss==3.3.1.1\n",
      "lazy-object-proxy @ file:///C:/ci/lazy-object-proxy_1616529307648/work\n",
      "libarchive-c @ file:///tmp/build/80754af9/python-libarchive-c_1617780486945/work\n",
      "libclang==12.0.0\n",
      "llvmlite==0.36.0\n",
      "locket==0.2.1\n",
      "lxml @ file:///C:/ci/lxml_1616443455957/work\n",
      "Markdown==3.3.6\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib @ file:///C:/ci/matplotlib-suite_1613408055530/work\n",
      "mccabe==0.6.1\n",
      "menuinst==1.4.16\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.3.0\n",
      "mkl-random @ file:///C:/ci/mkl_random_1618854156666/work\n",
      "mkl-service==2.3.0\n",
      "mock @ file:///tmp/build/80754af9/mock_1607622725907/work\n",
      "more-itertools @ file:///tmp/build/80754af9/more-itertools_1613676688952/work\n",
      "mpmath==1.2.1\n",
      "msgpack @ file:///C:/ci/msgpack-python_1612287368835/work\n",
      "multipledispatch==0.6.0\n",
      "mypy-extensions==0.4.3\n",
      "navigator-updater==0.2.1\n",
      "nbclassic @ file:///tmp/build/80754af9/nbclassic_1616085367084/work\n",
      "nbclient @ file:///tmp/build/80754af9/nbclient_1614364831625/work\n",
      "nbconvert @ file:///C:/ci/nbconvert_1601914925608/work\n",
      "nbformat @ file:///tmp/build/80754af9/nbformat_1617383369282/work\n",
      "nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1613680548246/work\n",
      "networkx @ file:///tmp/build/80754af9/networkx_1598376031484/work\n",
      "nltk @ file:///tmp/build/80754af9/nltk_1618327084230/work\n",
      "nose @ file:///tmp/build/80754af9/nose_1606773131901/work\n",
      "notebook @ file:///C:/ci/notebook_1616443715883/work\n",
      "numba @ file:///C:/ci/numba_1616774458845/work\n",
      "numexpr @ file:///C:/ci/numexpr_1618856738664/work\n",
      "numpy @ file:///C:/ci/numpy_and_numpy_base_1618497418457/work\n",
      "numpydoc @ file:///tmp/build/80754af9/numpydoc_1605117425582/work\n",
      "oauthlib==3.1.1\n",
      "olefile==0.46\n",
      "openpyxl @ file:///tmp/build/80754af9/openpyxl_1615411699337/work\n",
      "\n",
      "opt-einsum==3.3.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could not generate requirement for distribution -pype1 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages): Parse error at \"'-pype1=='\": Expected W:(abcd...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "packaging @ file:///tmp/build/80754af9/packaging_1611952188834/work\n",
      "pandas @ file:///C:/ci/pandas_1618365634936/work\n",
      "pandocfilters @ file:///C:/ci/pandocfilters_1605102497129/work\n",
      "paramiko @ file:///tmp/build/80754af9/paramiko_1598886428689/work\n",
      "parso==0.7.0\n",
      "partd @ file:///tmp/build/80754af9/partd_1618000087440/work\n",
      "path @ file:///C:/ci/path_1614022440181/work\n",
      "pathlib2 @ file:///C:/ci/pathlib2_1607025069150/work\n",
      "pathspec==0.7.0\n",
      "patsy==0.5.1\n",
      "pep8==1.7.1\n",
      "pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\n",
      "pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\n",
      "Pillow @ file:///C:/ci/pillow_1617386341487/work\n",
      "pkginfo==1.7.0\n",
      "pluggy @ file:///C:/ci/pluggy_1615976358795/work\n",
      "ply==3.11\n",
      "prometheus-client @ file:///tmp/build/80754af9/prometheus_client_1618088486455/work\n",
      "prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1616415428029/work\n",
      "protobuf==3.19.3\n",
      "psutil @ file:///C:/ci/psutil_1612298324802/work\n",
      "ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "py @ file:///tmp/build/80754af9/py_1607971587848/work\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycodestyle @ file:///home/ktietz/src/ci_mi/pycodestyle_1612807597675/work\n",
      "pycosat==0.6.3\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1594388511720/work\n",
      "pycurl==7.43.0.6\n",
      "pydocstyle @ file:///tmp/build/80754af9/pydocstyle_1616182067796/work\n",
      "pyerfa @ file:///C:/ci/pyerfa_1619391071834/work\n",
      "pyflakes @ file:///home/ktietz/src/ci_ipy2/pyflakes_1612551159640/work\n",
      "Pygments @ file:///tmp/build/80754af9/pygments_1615143339740/work\n",
      "pylint @ file:///C:/ci/pylint_1617136058775/work\n",
      "pyls-black @ file:///tmp/build/80754af9/pyls-black_1607553132291/work\n",
      "pyls-spyder @ file:///tmp/build/80754af9/pyls-spyder_1613849700860/work\n",
      "PyNaCl @ file:///C:/ci/pynacl_1595000047588/work\n",
      "pyodbc===4.0.0-unsupported\n",
      "pyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1608057966937/work\n",
      "pyparsing @ file:///home/linux1/recipes/ci/pyparsing_1610983426697/work\n",
      "pyreadline==2.1\n",
      "pyrsistent @ file:///C:/ci/pyrsistent_1600141795814/work\n",
      "PySocks @ file:///C:/ci/pysocks_1605287845585/work\n",
      "pytest==6.2.3\n",
      "python-dateutil @ file:///home/ktietz/src/ci/python-dateutil_1611928101742/work\n",
      "python-jsonrpc-server @ file:///tmp/build/80754af9/python-jsonrpc-server_1600278539111/work\n",
      "python-language-server @ file:///tmp/build/80754af9/python-language-server_1607972495879/work\n",
      "pytz @ file:///tmp/build/80754af9/pytz_1612215392582/work\n",
      "PyWavelets @ file:///C:/ci/pywavelets_1601658407916/work\n",
      "pywin32==227\n",
      "pywin32-ctypes==0.2.0\n",
      "pywinpty==0.5.7\n",
      "PyYAML==5.4.1\n",
      "pyzmq==20.0.0\n",
      "QDarkStyle==2.8.1\n",
      "QtAwesome @ file:///tmp/build/80754af9/qtawesome_1615991616277/work\n",
      "qtconsole @ file:///tmp/build/80754af9/qtconsole_1616775094278/work\n",
      "QtPy==1.9.0\n",
      "regex @ file:///C:/ci/regex_1617569893741/work\n",
      "requests @ file:///tmp/build/80754af9/requests_1608241421344/work\n",
      "requests-oauthlib==1.3.0\n",
      "rope @ file:///tmp/build/80754af9/rope_1602264064449/work\n",
      "rsa==4.8\n",
      "Rtree @ file:///C:/ci/rtree_1618421009405/work\n",
      "ruamel-yaml-conda @ file:///C:/ci/ruamel_yaml_1616016967756/work\n",
      "sacremoses==0.0.47\n",
      "scikit-image==0.18.1\n",
      "scikit-learn @ file:///C:/ci/scikit-learn_1614446896245/work\n",
      "scipy @ file:///C:/ci/scipy_1618856128765/work\n",
      "seaborn @ file:///tmp/build/80754af9/seaborn_1608578541026/work\n",
      "Send2Trash @ file:///tmp/build/80754af9/send2trash_1607525499227/work\n",
      "sentencepiece==0.1.96\n",
      "simplegeneric==0.8.1\n",
      "singledispatch @ file:///tmp/build/80754af9/singledispatch_1614366001199/work\n",
      "sip==4.19.13\n",
      "six @ file:///C:/ci/six_1605187374963/work\n",
      "smart-open==5.2.1\n",
      "sniffio @ file:///C:/ci/sniffio_1614030707456/work\n",
      "snowballstemmer @ file:///tmp/build/80754af9/snowballstemmer_1611258885636/work\n",
      "sortedcollections @ file:///tmp/build/80754af9/sortedcollections_1611172717284/work\n",
      "sortedcontainers @ file:///tmp/build/80754af9/sortedcontainers_1606865132123/work\n",
      "soupsieve @ file:///tmp/build/80754af9/soupsieve_1616183228191/work\n",
      "Sphinx @ file:///tmp/build/80754af9/sphinx_1620777493457/work\n",
      "sphinxcontrib-applehelp @ file:///home/ktietz/src/ci/sphinxcontrib-applehelp_1611920841464/work\n",
      "sphinxcontrib-devhelp @ file:///home/ktietz/src/ci/sphinxcontrib-devhelp_1611920923094/work\n",
      "sphinxcontrib-htmlhelp @ file:///home/ktietz/src/ci/sphinxcontrib-htmlhelp_1611920974801/work\n",
      "sphinxcontrib-jsmath @ file:///home/ktietz/src/ci/sphinxcontrib-jsmath_1611920942228/work\n",
      "sphinxcontrib-qthelp @ file:///home/ktietz/src/ci/sphinxcontrib-qthelp_1611921055322/work\n",
      "sphinxcontrib-serializinghtml @ file:///home/ktietz/src/ci/sphinxcontrib-serializinghtml_1611920755253/work\n",
      "sphinxcontrib-websupport @ file:///tmp/build/80754af9/sphinxcontrib-websupport_1597081412696/work\n",
      "spyder @ file:///C:/ci/spyder_1616776239898/work\n",
      "spyder-kernels @ file:///C:/ci/spyder-kernels_1614030842607/work\n",
      "SQLAlchemy @ file:///C:/ci/sqlalchemy_1618090063261/work\n",
      "statsmodels==0.12.2\n",
      "sympy @ file:///C:/ci/sympy_1618255511605/work\n",
      "tables==3.6.1\n",
      "tblib @ file:///tmp/build/80754af9/tblib_1597928476713/work\n",
      "tensorboard==2.7.0\n",
      "tensorboard-data-server==0.6.1\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "tensorflow==2.7.0\n",
      "tensorflow-estimator==2.7.0\n",
      "tensorflow-io-gcs-filesystem==0.23.1\n",
      "termcolor==1.1.0\n",
      "terminado==0.9.4\n",
      "testpath @ file:///home/ktietz/src/ci/testpath_1611930608132/work\n",
      "textdistance @ file:///tmp/build/80754af9/textdistance_1612461398012/work\n",
      "threadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "three-merge @ file:///tmp/build/80754af9/three-merge_1607553261110/work\n",
      "tifffile @ file:///tmp/build/80754af9/tifffile_1619636090847/work\n",
      "tokenizers==0.10.3\n",
      "toml @ file:///tmp/build/80754af9/toml_1616166611790/work\n",
      "toolz @ file:///home/linux1/recipes/ci/toolz_1610987900194/work\n",
      "tornado @ file:///C:/ci/tornado_1606942392901/work\n",
      "tqdm @ file:///tmp/build/80754af9/tqdm_1615925068909/work\n",
      "traitlets @ file:///home/ktietz/src/ci/traitlets_1611929699868/work\n",
      "transformers==4.15.0\n",
      "typed-ast @ file:///C:/ci/typed-ast_1610466535590/work\n",
      "typing-extensions @ file:///home/ktietz/src/ci_mi/typing_extensions_1612808209620/work\n",
      "ujson @ file:///C:/ci/ujson_1611241570789/work\n",
      "unicodecsv==0.14.1\n",
      "urllib3 @ file:///tmp/build/80754af9/urllib3_1615837158687/work\n",
      "watchdog @ file:///C:/ci/watchdog_1612471251191/work\n",
      "wcwidth @ file:///tmp/build/80754af9/wcwidth_1593447189090/work\n",
      "webencodings==0.5.1\n",
      "Werkzeug @ file:///home/ktietz/src/ci/werkzeug_1611932622770/work\n",
      "widgetsnbextension==3.5.1\n",
      "win-inet-pton @ file:///C:/ci/win_inet_pton_1605306167264/work\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.12.1\n",
      "xlrd @ file:///tmp/build/80754af9/xlrd_1608072521494/work\n",
      "XlsxWriter @ file:///tmp/build/80754af9/xlsxwriter_1617224712951/work\n",
      "xlwings==0.23.0\n",
      "xlwt==1.3.0\n",
      "xmltodict==0.12.0\n",
      "yapf @ file:///tmp/build/80754af9/yapf_1615749224965/work\n",
      "zict==2.0.0\n",
      "zipp @ file:///tmp/build/80754af9/zipp_1615904174917/work\n",
      "zope.event==4.5.0\n",
      "zope.interface @ file:///C:/ci/zope.interface_1616357322857/work\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
